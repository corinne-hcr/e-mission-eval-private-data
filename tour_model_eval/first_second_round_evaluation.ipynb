{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.core.get_database as edb\n",
    "import emission.analysis.modelling.tour_model.similarity as similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emission.analysis.modelling.tour_model.get_request_percentage as grp\n",
    "import emission.analysis.modelling.tour_model.get_scores as gs\n",
    "import emission.analysis.modelling.tour_model.label_processing as lp\n",
    "import emission.analysis.modelling.tour_model.get_users as gu\n",
    "import emission.analysis.modelling.tour_model.data_preprocessing as preprocess\n",
    "import evaluation_pipeline as ep\n",
    "import matplotlib.pyplot as plt\n",
    "import get_plot as plot\n",
    "import emission.core.common as ecc\n",
    "import jsonpickle as jpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_uuid_obj = list(edb.get_profile_db().find({\"install_group\": \"participant\"}, {\"user_id\": 1, \"_id\": 0}))\n",
    "all_users = [u[\"user_id\"] for u in participant_uuid_obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all/valid user list\n",
    "user_ls, valid_users = gu.get_user_ls(all_users, radius)\n",
    "\n",
    "all_filename = []\n",
    "for a in range(len(all_users)):\n",
    "    df = pd.DataFrame(columns=['user','user_id','percentage of 1st round','homogeneity socre of 1st round','percentage of 2nd round',\n",
    "                              'homogeneity socre of 2nd roun','scores','lower boundary','distance percentage'])\n",
    "    user = all_users[a]\n",
    "    \n",
    "    trips = preprocess.read_data(user)\n",
    "    filter_trips = preprocess.filter_data(trips, radius)\n",
    "    print('user', a + 1, 'filter_trips len', len(filter_trips))\n",
    "\n",
    "    # filter out users that don't have enough valid labeled trips\n",
    "    if not gu.valid_user(filter_trips, trips):\n",
    "        continue\n",
    "    tune_idx, test_idx = preprocess.split_data(filter_trips)\n",
    "\n",
    "    # choose tuning/test set to run the model\n",
    "    # this step will use KFold (5 splits) to split the data into different subsets\n",
    "    # - tune: tuning set\n",
    "    # - test: test set\n",
    "    # Here we user a bigger part of the data for testing and a smaller part for tuning\n",
    "    tune_data = preprocess.get_subdata(filter_trips, test_idx)\n",
    "    test_data = preprocess.get_subdata(filter_trips, tune_idx)\n",
    "    \n",
    "    # tune data\n",
    "    for j in range(len(tune_data)):\n",
    "        # for tuning, we don't add kmeans for re-clustering. We just need to get tuning parameters\n",
    "        # - low: the lower boundary of the dendrogram. If the final distance of the dendrogram is lower than \"low\", \n",
    "        # this bin no need to be re-clutered.\n",
    "        # - dist_pct: the higher boundary of the dendrogram. If the final distance is higher than \"low\", \n",
    "        # the cutoff of the dendrogram is (the final distance of the dendrogram * dist_pct)\n",
    "        low,dist_pct = ep.tune(tune_data[j],radius,kmeans=False)\n",
    "        df.loc[j,'lower boundary']=low\n",
    "        df.loc[j,'distance percentage']=dist_pct\n",
    "\n",
    "    # testing\n",
    "    for k in range(len(test_data)):\n",
    "        low = df.loc[k,'lower boundary']\n",
    "        dist_pct = df.loc[k,'distance percentage']   \n",
    "        # for testing, we add kmeans to re-build the model\n",
    "        homo_first, percentage_first, homo_second, percentage_second, scores = ep.test(test_data[k],radius,low,dist_pct,kmeans=True)\n",
    "        \n",
    "        df.loc[k,'percentage of 1st round']=percentage_first\n",
    "        df.loc[k,'homogeneity socre of 1st round']=homo_first\n",
    "        df.loc[k,'percentage of 2nd round']=percentage_second\n",
    "        df.loc[k,'homogeneity socre of 2nd round']=homo_second\n",
    "        df.loc[k,'scores']=scores\n",
    "        df['user_id']=user\n",
    "        df['user']='user'+str(a+1)\n",
    "    filename = \"user_\"+str(user)+\".csv\"\n",
    "    all_filename.append(filename)\n",
    "    df.to_csv(filename,index=True,index_label='split')\n",
    " \n",
    "   \n",
    "    \n",
    "# collect filename in a file, use it to plot the scatter\n",
    "collect_filename = jpickle.dumps(all_filename)\n",
    "with open(\"collect_filename\", \"w\") as fd:\n",
    "    fd.write(collect_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
